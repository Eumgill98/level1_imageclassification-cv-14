/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
wandb: Currently logged in as: kimseungki1011 (seungki1011). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /opt/ml/personal_code/seungki/wandb/run-20230417_092415-0sre4d5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run EfficientnetB0_32_1e-05_centercrop_[look at augmentation name, experimenting one by one]
wandb: ‚≠êÔ∏è View project at https://wandb.ai/seungki1011/Augmentation%20comparison%20one%20by%20one
wandb: üöÄ View run at https://wandb.ai/seungki1011/Augmentation%20comparison%20one%20by%20one/runs/0sre4d5x
Namespace(augmentation='centercrop', augmentation_types='[look at augmentation name, experimenting one by one]', batch_size=32, config=None, criterion='focal', data_dir='/opt/ml/input/data/train/images', dataset='MaskSplitByProfileDataset', epochs=35, log_interval=20, lr=1e-05, lr_decay_step=5, model='EfficientnetB0', model_dir='./model', name='EfficientnetB0', optimizer='Adam', resize=[380, 380], schedular=None, seed=42, val_ratio=0.2, valid_batch_size=256)
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: üöÄ View run EfficientnetB0_32_1e-05_centercrop_[look at augmentation name, experimenting one by one] at: https://wandb.ai/seungki1011/Augmentation%20comparison%20one%20by%20one/runs/0sre4d5x
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230417_092415-0sre4d5x/logs
Traceback (most recent call last):
  File "train.py", line 420, in <module>
    train(data_dir, model_dir, args)
  File "train.py", line 191, in train
    outs = model(inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/personal_code/seungki/model.py", line 48, in forward
    x = self.backbone(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/timm/models/efficientnet.py", line 557, in forward
    x = self.forward_features(x)
  File "/opt/conda/lib/python3.8/site-packages/timm/models/efficientnet.py", line 545, in forward_features
    x = self.blocks(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/timm/models/efficientnet_blocks.py", line 182, in forward
    x = self.bn1(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/timm/models/layers/norm_act.py", line 112, in forward
    x = self.act(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 394, in forward
    return F.silu(input, inplace=self.inplace)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py", line 1740, in silu
    return torch._C._nn.silu_(input)
RuntimeError: CUDA out of memory. Tried to allocate 424.00 MiB (GPU 0; 31.75 GiB total capacity; 2.00 GiB already allocated; 23.50 MiB free; 2.03 GiB reserved in total by PyTorch)
/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
wandb: Currently logged in as: kimseungki1011 (seungki1011). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /opt/ml/personal_code/seungki/wandb/run-20230417_092437-wkj5iypg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run EfficientnetB0_32_1e-05_randomerasing_[look at augmentation name, experimenting one by one]
wandb: ‚≠êÔ∏è View project at https://wandb.ai/seungki1011/Augmentation%20comparison%20one%20by%20one
wandb: üöÄ View run at https://wandb.ai/seungki1011/Augmentation%20comparison%20one%20by%20one/runs/wkj5iypg
Namespace(augmentation='randomerasing', augmentation_types='[look at augmentation name, experimenting one by one]', batch_size=32, config=None, criterion='focal', data_dir='/opt/ml/input/data/train/images', dataset='MaskSplitByProfileDataset', epochs=35, log_interval=20, lr=1e-05, lr_decay_step=5, model='EfficientnetB0', model_dir='./model', name='EfficientnetB0', optimizer='Adam', resize=[380, 380], schedular=None, seed=42, val_ratio=0.2, valid_batch_size=256)
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: üöÄ View run EfficientnetB0_32_1e-05_randomerasing_[look at augmentation name, experimenting one by one] at: https://wandb.ai/seungki1011/Augmentation%20comparison%20one%20by%20one/runs/wkj5iypg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230417_092437-wkj5iypg/logs
Traceback (most recent call last):
  File "train.py", line 420, in <module>
    train(data_dir, model_dir, args)
  File "train.py", line 191, in train
    outs = model(inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/personal_code/seungki/model.py", line 48, in forward
    x = self.backbone(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/timm/models/efficientnet.py", line 557, in forward
    x = self.forward_features(x)
  File "/opt/conda/lib/python3.8/site-packages/timm/models/efficientnet.py", line 545, in forward_features
    x = self.blocks(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/timm/models/efficientnet_blocks.py", line 182, in forward
    x = self.bn1(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/timm/models/layers/norm_act.py", line 112, in forward
    x = self.act(x)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 394, in forward
    return F.silu(input, inplace=self.inplace)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py", line 1740, in silu
    return torch._C._nn.silu_(input)
RuntimeError: CUDA out of memory. Tried to allocate 424.00 MiB (GPU 0; 31.75 GiB total capacity; 2.00 GiB already allocated; 23.50 MiB free; 2.03 GiB reserved in total by PyTorch)
/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
wandb: Currently logged in as: kimseungki1011 (seungki1011). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /opt/ml/personal_code/seungki/wandb/run-20230417_092458-oyj9wnb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run EfficientnetB0_32_1e-05_randomhorizontalflip_[look at augmentation name, experimenting one by one]
wandb: ‚≠êÔ∏è View project at https://wandb.ai/seungki1011/Augmentation%20comparison%20one%20by%20one
wandb: üöÄ View run at https://wandb.ai/seungki1011/Augmentation%20comparison%20one%20by%20one/runs/oyj9wnb0
Namespace(augmentation='randomhorizontalflip', augmentation_types='[look at augmentation name, experimenting one by one]', batch_size=32, config=None, criterion='focal', data_dir='/opt/ml/input/data/train/images', dataset='MaskSplitByProfileDataset', epochs=35, log_interval=20, lr=1e-05, lr_decay_step=5, model='EfficientnetB0', model_dir='./model', name='EfficientnetB0', optimizer='Adam', resize=[380, 380], schedular=None, seed=42, val_ratio=0.2, valid_batch_size=256)
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.002 MB of 0.002 MB uploaded (0.000 MB deduped)